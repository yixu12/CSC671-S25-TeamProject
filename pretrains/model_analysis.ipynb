{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb28608",
   "metadata": {},
   "source": [
    "# Model Analysis with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0012cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64af303",
   "metadata": {},
   "source": [
    "### File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74245111",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../data/Test\"\n",
    "input_parameters = \"model_parameters_efficientnetb0_224/best_test_acc/model_weights.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46ee1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4718b5",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04f76f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_s, efficientnet_b0\n",
    "model = torchvision.models.efficientnet_b0(weights=None)\n",
    "\n",
    "batch_size = 16\n",
    "img_size = 224 # 224 for efficientnet_b0, 384 for efficientnet_v2_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c168f23",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb70823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputed mean and std\n",
    "# for EfficientNetB0 and batch=16\n",
    "# mean, std = calculate_mean_std()\n",
    "mean = [0.7505297064781189, 0.5858979821205139, 0.5854080319404602]\n",
    "std = [0.1179748997092247, 0.14000017940998077, 0.15512846410274506]\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90e95aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes: 9\n",
      "Class counts: [16, 16, 16, 16, 16, 16, 3, 16, 3]\n",
      "Classes: ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
     ]
    }
   ],
   "source": [
    "class_counts = [0] * len(test_dataset.classes)\n",
    "for _, label in test_dataset.samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "print(f\"Total Classes: {len(test_dataset.classes)}\")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Classes: {test_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c72cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputed class weights of training set\n",
    "train_class_weights = [2.1823, 0.6616, 2.6187, 0.5680, 0.6969, 0.5385, 3.2309, 1.3745, 1.7898]\n",
    "class_weights = torch.tensor(train_class_weights, dtype=torch.float32).to(device)\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2409d",
   "metadata": {},
   "source": [
    "### Configure classifier and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf687765",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(test_dataset.classes)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    \n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.LeakyReLU(),\n",
    "\n",
    "    nn.Linear(256, num_classes),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1c4fe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(input_parameters, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb112e4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b864287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9635, Test Acc: 74.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "arr_predicted = []\n",
    "arr_labels = []\n",
    "arr_outputs = []\n",
    "\n",
    "test_bar = tqdm(test_loader, desc=f\"Testing:\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        # Collect predictions and true labels\n",
    "        arr_predicted.extend(predicted.cpu().numpy())\n",
    "        arr_labels.extend(labels.cpu().numpy())\n",
    "        arr_outputs.extend(F.softmax(outputs, dim=1).cpu().numpy())  # Probabilities for AUC-ROC\n",
    "\n",
    "        # Update progress bar\n",
    "        test_bar.set_postfix({\n",
    "            'loss': f\"{test_loss / total_test:.4f}\",\n",
    "            'acc': f\"{100. * correct_test / total_test:.2f}%\"\n",
    "        })\n",
    "    \n",
    "# Print test loss and accuracy\n",
    "test_acc = 100. * correct_test / total_test\n",
    "print(f\"Test Loss: {test_loss / total_test:.4f}, Test Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d18ab5",
   "metadata": {},
   "source": [
    "### Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8575c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: The proportion of correctly classified samples.\n",
    "# Precision: The proportion of true positives out of all predicted positives.\n",
    "# Recall: The proportion of true positives out of all actual positives.\n",
    "# F1-Score: The harmonic mean of precision and recall.\n",
    "# AUC-ROC: Measures the ability of the model to distinguish between classes. \n",
    "#          For multi-class, it uses the One-vs-Rest (OvR) strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78db8957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7458\n",
      "Precision: 0.7740\n",
      "Recall: 0.7458\n",
      "F1-Score: 0.7322\n",
      "AUC-ROC: 0.9551\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "arr_labels = np.array(arr_labels)\n",
    "arr_predicted = np.array(arr_predicted)\n",
    "arr_outputs = np.array(arr_outputs)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(arr_labels, arr_predicted)\n",
    "precision = precision_score(arr_labels, arr_predicted, average='weighted', zero_division=0)\n",
    "recall = recall_score(arr_labels, arr_predicted, average='weighted', zero_division=0)\n",
    "f1 = f1_score(arr_labels, arr_predicted, average='weighted')\n",
    "# AUC-ROC (One-vs-Rest for multi-class)\n",
    "auc_roc = roc_auc_score(arr_labels, arr_outputs, multi_class='ovr')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC671-S25-TeamProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
