{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e212769df2c79163",
   "metadata": {},
   "source": [
    "# Test with pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa5d0748a13767e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.142931Z",
     "start_time": "2025-04-21T11:48:31.294135Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import cpuinfo\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460da8d92d8804f",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7143543ffa0b1711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.284882Z",
     "start_time": "2025-04-21T11:48:34.282781Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/Train\"    # paths for your training and testing dataset\n",
    "test_path = \"../data/Test\"\n",
    "input_parameter = \"\"            # paths for import and export custom model trainable parameters\n",
    "output_parameter = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61231f85",
   "metadata": {},
   "source": [
    "### Device of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a1c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "device_name = \"\"\n",
    "\n",
    "if device == torch.device(\"cuda\"):\n",
    "    device_name = torch.cuda.get_device_name(device)\n",
    "    print(f\"Using GPU: {device_name}\")\n",
    "else:\n",
    "    cpu_info = cpuinfo.get_cpu_info()\n",
    "    device_name = cpu_info['brand_raw']\n",
    "    print(f\"Using CPU: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21140ca",
   "metadata": {},
   "source": [
    "### Pretrain Model of use from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a34a8a8d04cb802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.447142Z",
     "start_time": "2025-04-21T11:48:34.298297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model EfficientNet\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "#model = efficientnet_b0(weights=None)\n",
    "model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "print(f\"Using model {type(model).__name__}\")\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 32 # adjust to your memory\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,            # learning rate\n",
    "    weight_decay=1e-5,  # L2 regularization\n",
    "    betas=(0.9, 0.999), # Adam beta parameters\n",
    ")\n",
    "scheduler = CosineAnnealingLR(  # learning rate scheduler\n",
    "    optimizer,\n",
    "    T_max=epochs,               # number of epochs before restart\n",
    "    eta_min=1e-6,               # minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332cc4f55b5e4bf",
   "metadata": {},
   "source": [
    "### Data Loader and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6bff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 16\n"
     ]
    }
   ],
   "source": [
    "# Get dataset mean and std\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "num_workers = min(4, os.cpu_count() // 2)  # Dynamically set num_workers\n",
    "def compute_mean_std(dataset_path, batch_size=32, num_workers=None):\n",
    "    \"\"\"Compute channel-wise mean and standard deviation of an image dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to dataset directory (ImageFolder format)\n",
    "        batch_size: Number of images per batch\n",
    "        num_workers: Number of parallel data loading workers\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (mean, std) tensors for each channel (3 for RGB)\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),          # Resize shorter side to 256\n",
    "        transforms.CenterCrop(224),      # Take center 224x224 crop\n",
    "        transforms.ToTensor()            # Convert to [0,1] range tensor\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,                  # Maintain deterministic order\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    mean = 0.0                          # Accumulator for mean values\n",
    "    std = 0.0                           # Accumulator for std values \n",
    "    n_images = 0                        # Total images processed\n",
    "\n",
    "    for images, _ in tqdm(loader, desc=\"Computing mean/std\"):\n",
    "        batch_size = images.size(0)\n",
    "        # Flatten spatial dimensions (height x width)\n",
    "        images = images.view(batch_size, images.size(1), -1)  # (B, C, H*W)\n",
    "\n",
    "        # Compute mean across spatial dimensions\n",
    "        mean += images.mean(2).sum(0)   # Sum per-channel means (shape [C])\n",
    "\n",
    "        # Compute unbiased std across spatial dimensions\n",
    "        std += torch.std(images, dim=2, unbiased=True).sum(0)  # [C]\n",
    "\n",
    "        n_images += batch_size\n",
    "\n",
    "    # Average across all images\n",
    "    mean /= n_images\n",
    "    std /= n_images\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6282c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_train, std_train = compute_mean_std(train_path)\n",
    "#print(f\"Train mean: {mean_train}, Train std: {std_train}\")\n",
    "#mean_test, std_test = compute_mean_std(test_path)\n",
    "#print(f\"Test mean: {mean_test}, Test std: {std_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0a404b216b26a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.517225Z",
     "start_time": "2025-04-21T11:48:34.493177Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n",
      "Class weights: tensor([2.1823, 0.6616, 2.6187, 0.5680, 0.6969, 0.5385, 3.2309, 1.3745, 1.7898],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Transform for training and testing datasets\n",
    "transform_train = transforms.Compose([          # on training dataset\n",
    "    transforms.RandomRotation(degrees=30),          # Rotate images by up to 30 degrees\n",
    "\n",
    "    # transforms.RandomAffine(\n",
    "    #     degrees=0,                                  # No additional rotation\n",
    "    #     translate=(0.2, 0.2),                       # Shift width and height by up to 20%\n",
    "    #     shear=20                                    # Shear transformation\n",
    "    # ),\n",
    "\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.2)),    # Zoom in/out by up to 20%\n",
    "    transforms.RandomHorizontalFlip(p=0.5),                             # Randomly flip images horizontally\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1  # Randomly adjust brightness, contrast, saturation, and hue\n",
    "    ),\n",
    "\n",
    "    transforms.ToTensor(),                          # Convert image to tensor\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "    #transforms.Normalize(mean=mean_train.tolist(), std=std_train.tolist())\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([   # on test dataset\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    #transforms.Normalize(mean=mean_train.tolist(), std=std_train.tolist())\n",
    "    ])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "train_data = [\n",
    "    (images.to(device), labels.to(device))\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Preloading Train Data to {device_name}\", leave=False)\n",
    "]\n",
    "val_data = [\n",
    "    (images.to(device), labels.to(device))\n",
    "    for images, labels in tqdm(test_loader, desc=f\"Preloading Val Data to {device_name}\", leave=False)\n",
    "]\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "\n",
    "class_counts = [0] * len(train_dataset.classes)\n",
    "for _, label in train_dataset.samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(train_dataset.classes)),\n",
    "    y=[label for _, label in train_dataset.samples]\n",
    ")\n",
    "\n",
    "# Convert to a tensor for PyTorch\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Use the class weights in the loss function\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c2871148fc4fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.524281Z",
     "start_time": "2025-04-21T11:48:34.521216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier - Input features: 1280, Output classes: 9\n"
     ]
    }
   ],
   "source": [
    "# Edit the output layer of the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_features = model.classifier[1].in_features\n",
    "print(f\"Classifier - Input features: {num_features}, Output classes: {num_classes}\")\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_features, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(1024, num_classes),\n",
    "    #nn.Softmax(dim=1)  # Use Softmax for multi-class classification (may not be needed for CrossEntropyLoss)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1795a45e3c08a75",
   "metadata": {},
   "source": [
    "### Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda5db7349fc7d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.565876Z",
     "start_time": "2025-04-21T11:48:34.563196Z"
    }
   },
   "outputs": [],
   "source": [
    "# IF NEEDED\n",
    "# Load custom weight and optimizer states\n",
    "# if os.path.exists(input_parameter):\n",
    "#     checkpoint = torch.load(\"test_weights.pth\", map_location=device)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded31e95efe3a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.588042Z",
     "start_time": "2025-04-21T11:48:34.585548Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Selective layer freezing\n",
    "# # change base on your model\n",
    "# # \"Early layers are often already well-optimized\" by ChatGPT-O4\n",
    "# for _, param in model.named_parameters():\n",
    "#     param.requires_grad = True          # Unfreeze all layers first\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"classifier\" not in name:\n",
    "#         param.requires_grad = False     # Freeze everything except the last classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3247b01c5c37b276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.687917Z",
     "start_time": "2025-04-21T11:48:34.598546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "print(f\"Model is on {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69e6c43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "Layer (type:depth-idx)                                  Output Shape              Param #\n",
      "=========================================================================================================\n",
      "EfficientNet                                            [32, 9]                   --\n",
      "├─Sequential: 1-1                                       [32, 1280, 7, 7]          --\n",
      "│    └─Conv2dNormActivation: 2-1                        [32, 32, 112, 112]        --\n",
      "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
      "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
      "│    │    └─SiLU: 3-3                                   [32, 32, 112, 112]        --\n",
      "│    └─Sequential: 2-2                                  [32, 16, 112, 112]        --\n",
      "│    │    └─MBConv: 3-4                                 [32, 16, 112, 112]        1,448\n",
      "│    └─Sequential: 2-3                                  [32, 24, 56, 56]          --\n",
      "│    │    └─MBConv: 3-5                                 [32, 24, 56, 56]          6,004\n",
      "│    │    └─MBConv: 3-6                                 [32, 24, 56, 56]          10,710\n",
      "│    └─Sequential: 2-4                                  [32, 40, 28, 28]          --\n",
      "│    │    └─MBConv: 3-7                                 [32, 40, 28, 28]          15,350\n",
      "│    │    └─MBConv: 3-8                                 [32, 40, 28, 28]          31,290\n",
      "│    └─Sequential: 2-5                                  [32, 80, 14, 14]          --\n",
      "│    │    └─MBConv: 3-9                                 [32, 80, 14, 14]          37,130\n",
      "│    │    └─MBConv: 3-10                                [32, 80, 14, 14]          102,900\n",
      "│    │    └─MBConv: 3-11                                [32, 80, 14, 14]          102,900\n",
      "│    └─Sequential: 2-6                                  [32, 112, 14, 14]         --\n",
      "│    │    └─MBConv: 3-12                                [32, 112, 14, 14]         126,004\n",
      "│    │    └─MBConv: 3-13                                [32, 112, 14, 14]         208,572\n",
      "│    │    └─MBConv: 3-14                                [32, 112, 14, 14]         208,572\n",
      "│    └─Sequential: 2-7                                  [32, 192, 7, 7]           --\n",
      "│    │    └─MBConv: 3-15                                [32, 192, 7, 7]           262,492\n",
      "│    │    └─MBConv: 3-16                                [32, 192, 7, 7]           587,952\n",
      "│    │    └─MBConv: 3-17                                [32, 192, 7, 7]           587,952\n",
      "│    │    └─MBConv: 3-18                                [32, 192, 7, 7]           587,952\n",
      "│    └─Sequential: 2-8                                  [32, 320, 7, 7]           --\n",
      "│    │    └─MBConv: 3-19                                [32, 320, 7, 7]           717,232\n",
      "│    └─Conv2dNormActivation: 2-9                        [32, 1280, 7, 7]          --\n",
      "│    │    └─Conv2d: 3-20                                [32, 1280, 7, 7]          409,600\n",
      "│    │    └─BatchNorm2d: 3-21                           [32, 1280, 7, 7]          2,560\n",
      "│    │    └─SiLU: 3-22                                  [32, 1280, 7, 7]          --\n",
      "├─AdaptiveAvgPool2d: 1-2                                [32, 1280, 1, 1]          --\n",
      "├─Sequential: 1-3                                       [32, 9]                   --\n",
      "│    └─Dropout: 2-10                                    [32, 1280]                --\n",
      "│    └─Linear: 2-11                                     [32, 1024]                1,311,744\n",
      "│    └─BatchNorm1d: 2-12                                [32, 1024]                2,048\n",
      "│    └─ReLU: 2-13                                       [32, 1024]                --\n",
      "│    └─Dropout: 2-14                                    [32, 1024]                --\n",
      "│    └─Linear: 2-15                                     [32, 9]                   9,225\n",
      "=========================================================================================================\n",
      "Total params: 5,330,565\n",
      "Trainable params: 5,330,565\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 12.35\n",
      "=========================================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 3452.62\n",
      "Params size (MB): 21.32\n",
      "Estimated Total Size (MB): 3493.21\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print model architecture\n",
    "print(summary(model, (batch_size, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22466871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG\n",
    "# print(f\"Model device: {next(model.parameters()).device}\")\n",
    "# for images, labels in train_data:\n",
    "#     print(f\"Input device: {images.device}\")\n",
    "#     break\n",
    "# print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027cba37344acf9",
   "metadata": {},
   "source": [
    "### Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3520fd42aeea885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.251397Z",
     "start_time": "2025-04-21T11:48:34.690910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 2.1385, Train Acc: 16.93% | Val Loss: 1.9562, Val Acc: 40.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train Loss: 1.6967, Train Acc: 35.19% | Val Loss: 1.5424, Val Acc: 47.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train Loss: 1.3270, Train Acc: 49.04% | Val Loss: 1.3466, Val Acc: 54.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train Loss: 1.0441, Train Acc: 60.34% | Val Loss: 1.2682, Val Acc: 56.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train Loss: 0.8308, Train Acc: 69.90% | Val Loss: 1.2474, Val Acc: 58.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train Loss: 0.6551, Train Acc: 76.78% | Val Loss: 1.3003, Val Acc: 59.32%\n",
      "Validation loss did not improve from 1.2474. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train Loss: 1.0511, Train Acc: 64.00% | Val Loss: 1.1677, Val Acc: 57.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train Loss: 0.7036, Train Acc: 74.63% | Val Loss: 1.2161, Val Acc: 60.17%\n",
      "Validation loss did not improve from 1.1677. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train Loss: 0.8796, Train Acc: 66.32% | Val Loss: 1.1957, Val Acc: 61.02%\n",
      "Validation loss did not improve from 1.1677. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train Loss: 0.8375, Train Acc: 67.84% | Val Loss: 1.1288, Val Acc: 61.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train Loss: 0.5670, Train Acc: 78.38% | Val Loss: 1.1654, Val Acc: 65.25%\n",
      "Validation loss did not improve from 1.1288. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 - Train Loss: 0.6982, Train Acc: 74.10% | Val Loss: 1.1025, Val Acc: 66.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 - Train Loss: 0.4956, Train Acc: 82.18% | Val Loss: 1.0601, Val Acc: 66.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 - Train Loss: 0.3840, Train Acc: 88.03% | Val Loss: 1.1252, Val Acc: 67.80%\n",
      "Validation loss did not improve from 1.0601. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/60 - Train Loss: 0.5984, Train Acc: 78.38% | Val Loss: 1.1193, Val Acc: 66.95%\n",
      "Validation loss did not improve from 1.0601. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60 - Train Loss: 0.6072, Train Acc: 77.09% | Val Loss: 0.9112, Val Acc: 66.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/60 - Train Loss: 0.4243, Train Acc: 85.71% | Val Loss: 1.0134, Val Acc: 65.25%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/60 - Train Loss: 0.5598, Train Acc: 79.46% | Val Loss: 1.0345, Val Acc: 69.49%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60 - Train Loss: 0.5501, Train Acc: 79.37% | Val Loss: 1.0598, Val Acc: 70.34%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/60 - Train Loss: 0.4907, Train Acc: 80.97% | Val Loss: 0.9438, Val Acc: 71.19%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60 - Train Loss: 0.4647, Train Acc: 82.00% | Val Loss: 1.0708, Val Acc: 69.49%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/60 - Train Loss: 0.4434, Train Acc: 83.83% | Val Loss: 0.9577, Val Acc: 70.34%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/60 - Train Loss: 0.4403, Train Acc: 84.06% | Val Loss: 1.0063, Val Acc: 71.19%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60 - Train Loss: 0.4257, Train Acc: 84.64% | Val Loss: 0.9899, Val Acc: 70.34%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60 - Train Loss: 0.4409, Train Acc: 83.65% | Val Loss: 1.1079, Val Acc: 66.95%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60 - Train Loss: 0.3713, Train Acc: 86.82% | Val Loss: 1.0313, Val Acc: 71.19%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/60 - Train Loss: 0.3821, Train Acc: 86.20% | Val Loss: 1.0918, Val Acc: 71.19%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/60 - Train Loss: 0.3679, Train Acc: 86.74% | Val Loss: 1.0627, Val Acc: 72.88%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/60 - Train Loss: 0.3528, Train Acc: 87.23% | Val Loss: 1.0157, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/60 - Train Loss: 0.3411, Train Acc: 87.72% | Val Loss: 1.0246, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/60 - Train Loss: 0.3403, Train Acc: 87.99% | Val Loss: 0.9999, Val Acc: 74.58%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60 - Train Loss: 0.3275, Train Acc: 88.83% | Val Loss: 1.0570, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60 - Train Loss: 0.3441, Train Acc: 87.41% | Val Loss: 1.1893, Val Acc: 71.19%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/60 - Train Loss: 0.3176, Train Acc: 89.10% | Val Loss: 1.1538, Val Acc: 73.73%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/60 - Train Loss: 0.2956, Train Acc: 89.10% | Val Loss: 1.1369, Val Acc: 72.88%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/60 - Train Loss: 0.3019, Train Acc: 89.19% | Val Loss: 1.1424, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60 - Train Loss: 0.3079, Train Acc: 88.61% | Val Loss: 1.1886, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/60 - Train Loss: 0.2770, Train Acc: 90.40% | Val Loss: 1.1948, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/60 - Train Loss: 0.2810, Train Acc: 90.53% | Val Loss: 1.2526, Val Acc: 69.49%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/60 - Train Loss: 0.2816, Train Acc: 90.53% | Val Loss: 1.1781, Val Acc: 70.34%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/60 - Train Loss: 0.2671, Train Acc: 89.95% | Val Loss: 1.1854, Val Acc: 71.19%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/60 - Train Loss: 0.2773, Train Acc: 90.31% | Val Loss: 1.2702, Val Acc: 69.49%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60 - Train Loss: 0.2682, Train Acc: 90.75% | Val Loss: 1.2348, Val Acc: 70.34%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/60 - Train Loss: 0.2671, Train Acc: 90.71% | Val Loss: 1.2477, Val Acc: 69.49%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/60 - Train Loss: 0.2788, Train Acc: 90.00% | Val Loss: 1.2554, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60 - Train Loss: 0.2469, Train Acc: 91.56% | Val Loss: 1.2437, Val Acc: 72.03%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60 - Train Loss: 0.2547, Train Acc: 91.02% | Val Loss: 1.2670, Val Acc: 69.49%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/60 - Train Loss: 0.2480, Train Acc: 91.78% | Val Loss: 1.2759, Val Acc: 68.64%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60 - Train Loss: 0.2655, Train Acc: 90.80% | Val Loss: 1.2559, Val Acc: 66.95%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60 - Train Loss: 0.2501, Train Acc: 91.42% | Val Loss: 1.3032, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60 - Train Loss: 0.2479, Train Acc: 91.42% | Val Loss: 1.2588, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/60 - Train Loss: 0.2474, Train Acc: 91.38% | Val Loss: 1.2931, Val Acc: 66.95%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/60 - Train Loss: 0.2577, Train Acc: 91.16% | Val Loss: 1.3068, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60 - Train Loss: 0.2473, Train Acc: 91.60% | Val Loss: 1.3112, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/60 - Train Loss: 0.2427, Train Acc: 91.56% | Val Loss: 1.2465, Val Acc: 68.64%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/60 - Train Loss: 0.2509, Train Acc: 90.84% | Val Loss: 1.3338, Val Acc: 65.25%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60 - Train Loss: 0.2448, Train Acc: 91.65% | Val Loss: 1.2270, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60 - Train Loss: 0.2391, Train Acc: 91.65% | Val Loss: 1.3129, Val Acc: 66.95%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60 - Train Loss: 0.2394, Train Acc: 91.60% | Val Loss: 1.2763, Val Acc: 67.80%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60 - Train Loss: 0.2444, Train Acc: 91.83% | Val Loss: 1.2442, Val Acc: 68.64%\n",
      "Validation loss did not improve from 0.9112. Augmenting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "previous_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    train_bar = tqdm(train_data, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "    for images, labels in train_bar:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'loss': f\"{running_loss / total_train:.4f}\",\n",
    "            'acc': f\"{100. * correct_train / total_train:.2f}%\"\n",
    "        })\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    val_bar = tqdm(val_data, desc=f\"Epoch {epoch + 1}/{epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_bar:\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            val_bar.set_postfix({\n",
    "                'loss': f\"{val_loss / total_val:.4f}\",\n",
    "                'acc': f\"{100. * correct_val / total_val:.2f}%\"\n",
    "            })\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - \"\n",
    "          f\"Train Loss: {running_loss / total_train:.4f}, Train Acc: {100. * correct_train / total_train:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss / total_val:.4f}, Val Acc: {100. * correct_val / total_val:.2f}%\")\n",
    "    \n",
    "    # Augment the dataset if validation loss is not improving\n",
    "    if val_loss > previous_loss:\n",
    "        times = 0\n",
    "        print(f\"Validation loss did not improve from {previous_loss / total_val:.4f}. Augmenting dataset...\")\n",
    "        del train_data\n",
    "        torch.cuda.empty_cache()\n",
    "        train_dataset = datasets.ImageFolder(root=train_path, transform=transform_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        train_data = [\n",
    "            (images.to(device), labels.to(device))\n",
    "            for images, labels in tqdm(train_loader, desc=f\"Preloading Train Data to {device_name}\", leave=False)\n",
    "        ]\n",
    "    previous_loss = min(val_loss, previous_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f05590085d19fe",
   "metadata": {},
   "source": [
    "### Training log and data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbef08ee604230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.411762Z",
     "start_time": "2025-04-21T12:11:52.409200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "# iteration 4 template 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC671-S25-TeamProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
