{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e212769df2c79163",
   "metadata": {},
   "source": [
    "## Test with pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa5d0748a13767e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.142931Z",
     "start_time": "2025-04-21T11:48:31.294135Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import time\n",
    "import cpuinfo\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460da8d92d8804f",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7143543ffa0b1711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.284882Z",
     "start_time": "2025-04-21T11:48:34.282781Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/Train\"    # paths for your training and testing dataset\n",
    "test_path = \"../data/Test\"\n",
    "input_parameter = \"\"            # paths for import and export custom model trainable parameters\n",
    "output_parameter = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f7a2a4da470e3e",
   "metadata": {},
   "source": [
    "### Pretrain Model of use from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a34a8a8d04cb802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.447142Z",
     "start_time": "2025-04-21T11:48:34.298297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model DenseNet\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "print(f\"Using model {type(model).__name__}\")\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 8 # adjust to your memory\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,            # learning rate\n",
    "    weight_decay=1e-4,  # L2 regularization\n",
    "    betas=(0.9, 0.999), # Adam beta parameters\n",
    ")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(  # learning rate scheduler\n",
    "    optimizer,\n",
    "    T_max=epochs,               # number of epochs before restart\n",
    "    eta_min=1e-6,               # minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36de4213559fc515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.465665Z",
     "start_time": "2025-04-21T11:48:34.457418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff6240d7470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442bebb505eb1bb",
   "metadata": {},
   "source": [
    "### Data Preprocess Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b2ef1842f83dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.481085Z",
     "start_time": "2025-04-21T11:48:34.477096Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([  # on training dataset\n",
    "    transforms.RandomRotation(degrees=10),  # introduce varieties for better generalization\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet1K stats\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([   # on test dataset\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332cc4f55b5e4bf",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0a404b216b26a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.517225Z",
     "start_time": "2025-04-21T11:48:34.493177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 16\n",
      "Classes: ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform_test)\n",
    "\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "num_workers = min(4, os.cpu_count() // 2)  # Dynamically set num_workers\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c2871148fc4fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.524281Z",
     "start_time": "2025-04-21T11:48:34.521216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the output layer of the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=num_features, out_features=512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=512, out_features=num_classes),\n",
    "    nn.Softmax(dim=1)  # Use Softmax for multi-class classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb341e63ac3245",
   "metadata": {},
   "source": [
    "### Device of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b004d517792bc90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.554176Z",
     "start_time": "2025-04-21T11:48:34.535550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU: 13th Gen Intel(R) Core(TM) i5-13500H\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "\n",
    "if device == torch.device(\"cuda\"):\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    cpu_info = cpuinfo.get_cpu_info()\n",
    "    print(f\"Using CPU: {cpu_info['brand_raw']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1795a45e3c08a75",
   "metadata": {},
   "source": [
    "### Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda5db7349fc7d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.565876Z",
     "start_time": "2025-04-21T11:48:34.563196Z"
    }
   },
   "outputs": [],
   "source": [
    "# IF NEEDED\n",
    "# Load custom weight and optimizer states\n",
    "# if os.path.exists(input_parameter):\n",
    "#     checkpoint = torch.load(\"test_weights.pth\", map_location=device)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded31e95efe3a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.588042Z",
     "start_time": "2025-04-21T11:48:34.585548Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Selective layer freezing\n",
    "# # change base on your model\n",
    "# # \"Early layers are often already well-optimized\" by ChatGPT-O4\n",
    "# for _, param in model.named_parameters():\n",
    "#     param.requires_grad = True          # Unfreeze all layers first\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"classifier\" not in name:\n",
    "#         param.requires_grad = False     # Freeze everything except fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3247b01c5c37b276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.687917Z",
     "start_time": "2025-04-21T11:48:34.598546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cpu\n"
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "print(f\"Model is on {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69e6c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DenseNet                                 [8, 9]                    --\n",
       "├─Sequential: 1-1                        [8, 1024, 7, 7]           --\n",
       "│    └─Conv2d: 2-1                       [8, 64, 112, 112]         9,408\n",
       "│    └─BatchNorm2d: 2-2                  [8, 64, 112, 112]         128\n",
       "│    └─ReLU: 2-3                         [8, 64, 112, 112]         --\n",
       "│    └─MaxPool2d: 2-4                    [8, 64, 56, 56]           --\n",
       "│    └─_DenseBlock: 2-5                  [8, 256, 56, 56]          --\n",
       "│    │    └─_DenseLayer: 3-1             [8, 32, 56, 56]           45,440\n",
       "│    │    └─_DenseLayer: 3-2             [8, 32, 56, 56]           49,600\n",
       "│    │    └─_DenseLayer: 3-3             [8, 32, 56, 56]           53,760\n",
       "│    │    └─_DenseLayer: 3-4             [8, 32, 56, 56]           57,920\n",
       "│    │    └─_DenseLayer: 3-5             [8, 32, 56, 56]           62,080\n",
       "│    │    └─_DenseLayer: 3-6             [8, 32, 56, 56]           66,240\n",
       "│    └─_Transition: 2-6                  [8, 128, 28, 28]          --\n",
       "│    │    └─BatchNorm2d: 3-7             [8, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-8                    [8, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-9                  [8, 128, 56, 56]          32,768\n",
       "│    │    └─AvgPool2d: 3-10              [8, 128, 28, 28]          --\n",
       "│    └─_DenseBlock: 2-7                  [8, 512, 28, 28]          --\n",
       "│    │    └─_DenseLayer: 3-11            [8, 32, 28, 28]           53,760\n",
       "│    │    └─_DenseLayer: 3-12            [8, 32, 28, 28]           57,920\n",
       "│    │    └─_DenseLayer: 3-13            [8, 32, 28, 28]           62,080\n",
       "│    │    └─_DenseLayer: 3-14            [8, 32, 28, 28]           66,240\n",
       "│    │    └─_DenseLayer: 3-15            [8, 32, 28, 28]           70,400\n",
       "│    │    └─_DenseLayer: 3-16            [8, 32, 28, 28]           74,560\n",
       "│    │    └─_DenseLayer: 3-17            [8, 32, 28, 28]           78,720\n",
       "│    │    └─_DenseLayer: 3-18            [8, 32, 28, 28]           82,880\n",
       "│    │    └─_DenseLayer: 3-19            [8, 32, 28, 28]           87,040\n",
       "│    │    └─_DenseLayer: 3-20            [8, 32, 28, 28]           91,200\n",
       "│    │    └─_DenseLayer: 3-21            [8, 32, 28, 28]           95,360\n",
       "│    │    └─_DenseLayer: 3-22            [8, 32, 28, 28]           99,520\n",
       "│    └─_Transition: 2-8                  [8, 256, 14, 14]          --\n",
       "│    │    └─BatchNorm2d: 3-23            [8, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-24                   [8, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-25                 [8, 256, 28, 28]          131,072\n",
       "│    │    └─AvgPool2d: 3-26              [8, 256, 14, 14]          --\n",
       "│    └─_DenseBlock: 2-9                  [8, 1024, 14, 14]         --\n",
       "│    │    └─_DenseLayer: 3-27            [8, 32, 14, 14]           70,400\n",
       "│    │    └─_DenseLayer: 3-28            [8, 32, 14, 14]           74,560\n",
       "│    │    └─_DenseLayer: 3-29            [8, 32, 14, 14]           78,720\n",
       "│    │    └─_DenseLayer: 3-30            [8, 32, 14, 14]           82,880\n",
       "│    │    └─_DenseLayer: 3-31            [8, 32, 14, 14]           87,040\n",
       "│    │    └─_DenseLayer: 3-32            [8, 32, 14, 14]           91,200\n",
       "│    │    └─_DenseLayer: 3-33            [8, 32, 14, 14]           95,360\n",
       "│    │    └─_DenseLayer: 3-34            [8, 32, 14, 14]           99,520\n",
       "│    │    └─_DenseLayer: 3-35            [8, 32, 14, 14]           103,680\n",
       "│    │    └─_DenseLayer: 3-36            [8, 32, 14, 14]           107,840\n",
       "│    │    └─_DenseLayer: 3-37            [8, 32, 14, 14]           112,000\n",
       "│    │    └─_DenseLayer: 3-38            [8, 32, 14, 14]           116,160\n",
       "│    │    └─_DenseLayer: 3-39            [8, 32, 14, 14]           120,320\n",
       "│    │    └─_DenseLayer: 3-40            [8, 32, 14, 14]           124,480\n",
       "│    │    └─_DenseLayer: 3-41            [8, 32, 14, 14]           128,640\n",
       "│    │    └─_DenseLayer: 3-42            [8, 32, 14, 14]           132,800\n",
       "│    │    └─_DenseLayer: 3-43            [8, 32, 14, 14]           136,960\n",
       "│    │    └─_DenseLayer: 3-44            [8, 32, 14, 14]           141,120\n",
       "│    │    └─_DenseLayer: 3-45            [8, 32, 14, 14]           145,280\n",
       "│    │    └─_DenseLayer: 3-46            [8, 32, 14, 14]           149,440\n",
       "│    │    └─_DenseLayer: 3-47            [8, 32, 14, 14]           153,600\n",
       "│    │    └─_DenseLayer: 3-48            [8, 32, 14, 14]           157,760\n",
       "│    │    └─_DenseLayer: 3-49            [8, 32, 14, 14]           161,920\n",
       "│    │    └─_DenseLayer: 3-50            [8, 32, 14, 14]           166,080\n",
       "│    └─_Transition: 2-10                 [8, 512, 7, 7]            --\n",
       "│    │    └─BatchNorm2d: 3-51            [8, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-52                   [8, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-53                 [8, 512, 14, 14]          524,288\n",
       "│    │    └─AvgPool2d: 3-54              [8, 512, 7, 7]            --\n",
       "│    └─_DenseBlock: 2-11                 [8, 1024, 7, 7]           --\n",
       "│    │    └─_DenseLayer: 3-55            [8, 32, 7, 7]             103,680\n",
       "│    │    └─_DenseLayer: 3-56            [8, 32, 7, 7]             107,840\n",
       "│    │    └─_DenseLayer: 3-57            [8, 32, 7, 7]             112,000\n",
       "│    │    └─_DenseLayer: 3-58            [8, 32, 7, 7]             116,160\n",
       "│    │    └─_DenseLayer: 3-59            [8, 32, 7, 7]             120,320\n",
       "│    │    └─_DenseLayer: 3-60            [8, 32, 7, 7]             124,480\n",
       "│    │    └─_DenseLayer: 3-61            [8, 32, 7, 7]             128,640\n",
       "│    │    └─_DenseLayer: 3-62            [8, 32, 7, 7]             132,800\n",
       "│    │    └─_DenseLayer: 3-63            [8, 32, 7, 7]             136,960\n",
       "│    │    └─_DenseLayer: 3-64            [8, 32, 7, 7]             141,120\n",
       "│    │    └─_DenseLayer: 3-65            [8, 32, 7, 7]             145,280\n",
       "│    │    └─_DenseLayer: 3-66            [8, 32, 7, 7]             149,440\n",
       "│    │    └─_DenseLayer: 3-67            [8, 32, 7, 7]             153,600\n",
       "│    │    └─_DenseLayer: 3-68            [8, 32, 7, 7]             157,760\n",
       "│    │    └─_DenseLayer: 3-69            [8, 32, 7, 7]             161,920\n",
       "│    │    └─_DenseLayer: 3-70            [8, 32, 7, 7]             166,080\n",
       "│    └─BatchNorm2d: 2-12                 [8, 1024, 7, 7]           2,048\n",
       "├─Sequential: 1-2                        [8, 9]                    --\n",
       "│    └─Flatten: 2-13                     [8, 1024]                 --\n",
       "│    └─Dropout: 2-14                     [8, 1024]                 --\n",
       "│    └─Linear: 2-15                      [8, 512]                  524,800\n",
       "│    └─ReLU: 2-16                        [8, 512]                  --\n",
       "│    └─Linear: 2-17                      [8, 9]                    4,617\n",
       "│    └─Softmax: 2-18                     [8, 9]                    --\n",
       "==========================================================================================\n",
       "Total params: 7,483,273\n",
       "Trainable params: 7,483,273\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 22.67\n",
       "==========================================================================================\n",
       "Input size (MB): 4.82\n",
       "Forward/backward pass size (MB): 1444.30\n",
       "Params size (MB): 29.93\n",
       "Estimated Total Size (MB): 1479.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "test = densenet121()\n",
    "summary(model, (batch_size, 3, 224, 224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027cba37344acf9",
   "metadata": {},
   "source": [
    "### Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3520fd42aeea885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.251397Z",
     "start_time": "2025-04-21T11:48:34.690910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m images, labels = images.to(device), labels.to(device)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m outputs = model(images)\n\u001b[32m     15\u001b[39m loss = loss_function(outputs, labels)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torchvision/models/densenet.py:213\u001b[39m, in \u001b[36mDenseNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     features = \u001b[38;5;28mself\u001b[39m.features(x)\n\u001b[32m    214\u001b[39m     out = F.relu(features, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    215\u001b[39m     out = F.adaptive_avg_pool2d(out, (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torchvision/models/densenet.py:122\u001b[39m, in \u001b[36m_DenseBlock.forward\u001b[39m\u001b[34m(self, init_features)\u001b[39m\n\u001b[32m    120\u001b[39m features = [init_features]\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items():\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     new_features = layer(features)\n\u001b[32m    123\u001b[39m     features.append(new_features)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(features, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torchvision/models/densenet.py:88\u001b[39m, in \u001b[36m_DenseLayer.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     86\u001b[39m     bottleneck_output = \u001b[38;5;28mself\u001b[39m.call_checkpoint_bottleneck(prev_features)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     bottleneck_output = \u001b[38;5;28mself\u001b[39m.bn_function(prev_features)\n\u001b[32m     90\u001b[39m new_features = \u001b[38;5;28mself\u001b[39m.conv2(\u001b[38;5;28mself\u001b[39m.relu2(\u001b[38;5;28mself\u001b[39m.norm2(bottleneck_output)))\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.drop_rate > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torchvision/models/densenet.py:49\u001b[39m, in \u001b[36m_DenseLayer.bn_function\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) -> Tensor:\n\u001b[32m     48\u001b[39m     concated_features = torch.cat(inputs, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     bottleneck_output = \u001b[38;5;28mself\u001b[39m.conv1(\u001b[38;5;28mself\u001b[39m.relu1(\u001b[38;5;28mself\u001b[39m.norm1(concated_features)))  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/csc671wsl/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    550\u001b[39m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m.stride, \u001b[38;5;28mself\u001b[39m.padding, \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    551\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training loop with progress bar\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "    for images, labels in train_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'loss': f\"{running_loss / total_train:.4f}\",\n",
    "            'acc': f\"{100. * correct_train / total_train:.2f}%\"\n",
    "        })\n",
    "\n",
    "    # Calculate training statistics\n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = 100. * correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{epochs} [Val]\", leave=False)\n",
    "        for images, labels in val_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_bar.set_postfix({\n",
    "                'loss': f\"{val_loss / total_val:.4f}\",\n",
    "                'acc': f\"{100. * correct_val / total_val:.2f}%\"\n",
    "            })\n",
    "\n",
    "    # Calculate validation statistics\n",
    "    val_loss /= total_val\n",
    "    val_acc = 100. * correct_val / total_val\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f05590085d19fe",
   "metadata": {},
   "source": [
    "### Training log and data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbef08ee604230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.411762Z",
     "start_time": "2025-04-21T12:11:52.409200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "# iteration 2 template 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc671wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
