{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e212769df2c79163",
   "metadata": {},
   "source": [
    "# Test with pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5d0748a13767e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.142931Z",
     "start_time": "2025-04-21T11:48:31.294135Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.init as init\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cpuinfo\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18de51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control randomness\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460da8d92d8804f",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143543ffa0b1711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.284882Z",
     "start_time": "2025-04-21T11:48:34.282781Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/Train\"        # paths for your training and testing dataset\n",
    "#train_path = \"../data/aug_train\"    \n",
    "test_path = \"../data/Test\"          # using test dataset as validation too\n",
    "input_parameter = \"\"                # paths for import and export custom model trainable parameters\n",
    "output_parameter = \"./model_parameters_efficientnetb0_224\"  # paths for import and export custom model trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61231f85",
   "metadata": {},
   "source": [
    "### Device of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "device_name = \"\"\n",
    "\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "num_workers = min(4, os.cpu_count() // 2)  # Dynamically set num_workers\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21140ca",
   "metadata": {},
   "source": [
    "### Pretrain Model of use from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34a8a8d04cb802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.447142Z",
     "start_time": "2025-04-21T11:48:34.298297Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_s, efficientnet_b0\n",
    "model = efficientnet_b0(weights='DEFAULT')  # or efficientnet_v2_s(weights='DEFAULT')\n",
    "img_size = 224 # adjust input image size for model\n",
    "print(f\"Using model {type(model).__name__}\")\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16 # adjust to your memory\n",
    "\n",
    "# For classifier layer if used model freezing (disable when n < 0)\n",
    "n = 5\n",
    "optimizer = optim.AdamW(\n",
    "    [{\"params\": model.classifier.parameters(), \"lr\": 1e-2}],\n",
    "    weight_decay=1e-3,\n",
    "    )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    )\n",
    "\n",
    "# For fully unfrozen model after n epochs\n",
    "optimizer2 = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    )\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer2,\n",
    "    mode='max',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    cooldown=0,\n",
    "    threshold_mode='rel',\n",
    "    threshold=0.0001,\n",
    "    eps=1e-8\n",
    "    )\n",
    "if n < 0:\n",
    "    optimizer = optimizer2\n",
    "    scheduler = scheduler2\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss() defined in Weighed Cross Entropy Loss cell\n",
    "grad_clip = 5.0         # gradient clipping value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332cc4f55b5e4bf",
   "metadata": {},
   "source": [
    "### Data transform/normalization and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d91a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and std of dataset images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Initialize variables to compute mean and variance\n",
    "mean = 0.0\n",
    "var = 0.0\n",
    "total_images = 0\n",
    "\n",
    "for images, _ in tqdm(loader, desc=\"Calculating stats\"):\n",
    "    batch_samples = images.size(0)  # Number of images in the batch\n",
    "    images = images.view(batch_samples, images.size(1), -1)  # Flatten the image pixels [B, C, H*W]\n",
    "    \n",
    "    # Compute batch mean and variance\n",
    "    batch_mean = images.mean([0, 2])  # Mean for each channel\n",
    "    batch_var = images.var([0, 2])   # Variance for each channel\n",
    "    \n",
    "    # Update global mean and variance\n",
    "    mean += batch_mean * batch_samples\n",
    "    var += batch_var * batch_samples\n",
    "    total_images += batch_samples\n",
    "\n",
    "# Final mean and standard deviation\n",
    "mean /= total_images\n",
    "std = torch.sqrt(var / total_images)\n",
    "\n",
    "mean = mean.tolist()\n",
    "std = std.tolist()\n",
    "\n",
    "print(f\"Total Images: {total_images}\")\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a404b216b26a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.517225Z",
     "start_time": "2025-04-21T11:48:34.493177Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(450),\n",
    "    transforms.Pad(padding=150, padding_mode='reflect'),\n",
    "    transforms.RandomRotation(45, expand=False),\n",
    "    transforms.CenterCrop(450),\n",
    "    transforms.Resize(img_size),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.02),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),                     # Use the calculated mean and std\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Use the ImageNet mean and std\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.01, 0.05), ratio=(0.3, 10), value='random', inplace=False),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([   # on test dataset\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "val_data = [\n",
    "    (images.to(device), labels.to(device))\n",
    "    for images, labels in tqdm(test_loader, desc=f\"Preloading Test Data to {device_name}\", leave=False)\n",
    "]\n",
    "\n",
    "class_counts = [0] * len(train_dataset.classes)\n",
    "for _, label in train_dataset.samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "print(f\"Total Classes: {len(train_dataset.classes)}\")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Classes: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ea264",
   "metadata": {},
   "source": [
    "### Weighted Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0848f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.arange(len(train_dataset.classes)),\n",
    "    y=[label for _, label in train_dataset.samples]\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9adc1",
   "metadata": {},
   "source": [
    "### Model Classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2871148fc4fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.524281Z",
     "start_time": "2025-04-21T11:48:34.521216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the output layer of the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    \n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.LeakyReLU(),\n",
    "\n",
    "    nn.Linear(256, num_classes),\n",
    ")\n",
    "\n",
    "# Initialize weights and biases for classifier\n",
    "for m in model.classifier:\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight, mean=0, std=0.01, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)\n",
    "\n",
    "print(f\"Classifier - Input features: {num_features}, Output classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1795a45e3c08a75",
   "metadata": {},
   "source": [
    "### Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5db7349fc7d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.565876Z",
     "start_time": "2025-04-21T11:48:34.563196Z"
    }
   },
   "outputs": [],
   "source": [
    "# IF NEEDED\n",
    "# Load custom weight and optimizer states\n",
    "# if os.path.exists(input_parameter):\n",
    "#     checkpoint = torch.load(\"test_weights.pth\", map_location=device)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded31e95efe3a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.588042Z",
     "start_time": "2025-04-21T11:48:34.585548Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selective layer freezing\n",
    "# Freeze all layers except the classifier\n",
    "if n >= 0:\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "    for name, param in model.classifier.named_parameters():\n",
    "        param.requires_grad = True\n",
    "        print(f\"Unfreezing layer: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247b01c5c37b276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.687917Z",
     "start_time": "2025-04-21T11:48:34.598546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "print(f\"Model is on {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "# print(summary(model, (batch_size, 3, img_size, img_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22466871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG\n",
    "# print(f\"Model device: {next(model.parameters()).device}\")\n",
    "# for images, labels in train_data:\n",
    "#     print(f\"Input device: {images.device}\")\n",
    "#     break\n",
    "# print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027cba37344acf9",
   "metadata": {},
   "source": [
    "## Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3520fd42aeea885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.251397Z",
     "start_time": "2025-04-21T11:48:34.690910Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "arr_train_loss = []\n",
    "arr_train_acc = []\n",
    "arr_test_loss = []\n",
    "arr_test_acc = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Unfreeze at epoch n and reset optimizer and scheduler\n",
    "    if epoch == n:\n",
    "        optimizer = optimizer2\n",
    "        scheduler = scheduler2\n",
    "        for name, param in model.named_parameters():\n",
    "                param.requires_grad = True\n",
    "        print(\"Unfreezing all layers\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "    for images, labels in train_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # --Non-Mixed Precision training--\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        # --Non-Mixed Precision training--\n",
    "\n",
    "        # Calculate statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'loss': f\"{running_loss / total_train:.4f}\",\n",
    "            'acc': f\"{100. * correct_train / total_train:.2f}%\"\n",
    "        })\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    val_bar = tqdm(val_data, desc=f\"Epoch {epoch + 1}/{epochs} [Test]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_bar:\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            val_bar.set_postfix({\n",
    "                'loss': f\"{val_loss / total_val:.4f}\",\n",
    "                'acc': f\"{100. * correct_val / total_val:.2f}%\"\n",
    "            })\n",
    "\n",
    "    # Update learning rate\n",
    "    if isinstance(scheduler, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts) or isinstance(scheduler, torch.optim.lr_scheduler.CosineAnnealingLR):\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        scheduler.step(torch.tensor(correct_val / total_val))\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch + 1:>3}/{epochs} - \"\n",
    "          f\"LR: {current_lr:.7f} | \"\n",
    "          f\"Train Loss: {running_loss / total_train:.4f}, Train Acc: {100. * correct_train / total_train:.2f}% | \"\n",
    "          f\"Test Loss: {val_loss / total_val:.4f}, Test Acc: {100. * correct_val / total_val:.2f}%\")\n",
    "    \n",
    "    # Save training and validation loss and accuracy\n",
    "    arr_train_loss.append(running_loss / total_train)\n",
    "    arr_train_acc.append(100. * correct_train / total_train)\n",
    "    arr_test_loss.append(val_loss / total_val)\n",
    "    arr_test_acc.append(100. * correct_val / total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f05590085d19fe",
   "metadata": {},
   "source": [
    "### Training log and data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ada86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters\n",
    "if not os.path.exists(output_parameter):\n",
    "    os.makedirs(output_parameter)\n",
    "\n",
    "# Save model weights, optimizer state, and scheduler state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict()\n",
    "}, os.path.join(output_parameter, \"model_weights.pth\"))\n",
    "torch.save({\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, os.path.join(output_parameter, \"optimizer_weights.pth\"))\n",
    "torch.save({\n",
    "    'scheduler_state_dict': scheduler.state_dict()\n",
    "}, os.path.join(output_parameter, \"scheduler_weights.pth\"))\n",
    "\n",
    "# Save training logs to CSV\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, len(arr_train_loss) + 1)),\n",
    "    \"Train Loss\": arr_train_loss,\n",
    "    \"Train Accuracy\": arr_train_acc,\n",
    "    \"Test Loss\": arr_test_loss,\n",
    "    \"Test Accuracy\": arr_test_acc\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "csv_file = os.path.join(output_parameter, \"training_logs.csv\")\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbef08ee604230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.411762Z",
     "start_time": "2025-04-21T12:11:52.409200Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(arr_train_loss, label='Train Loss', color='blue', linestyle='-')\n",
    "plt.plot(arr_test_loss, label='Test Loss', color='red', linestyle='-')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(start=0, stop=len(arr_train_loss)+1, step=10))\n",
    "plt.xlim(-5, len(arr_train_loss))\n",
    "plt.yticks(np.arange(start=0, stop=max(arr_train_loss) + 0.5, step=0.25))\n",
    "plt.ylim(0, 2.5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(arr_train_acc, label='Train Acc', color='blue', linestyle='-')\n",
    "plt.plot(arr_test_acc, label='Test Acc', color='red', linestyle='-')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(start=0, stop=len(arr_train_loss)+1, step=10))\n",
    "plt.xlim(-5, len(arr_train_loss))\n",
    "plt.yticks(np.arange(start=max(min(arr_train_acc)//10*10-10, 0), stop=max(arr_train_acc)//10*10+30, step=10))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('loss_acc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e080da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 7 template 2\n",
    "# Updates:\n",
    "# 1. Use EfficientNetB0\n",
    "# 2. Implement gradual unfreezing\n",
    "# 3. Export model parameters\n",
    "# 4. Adjust data augmentation\n",
    "# 5. Use dataset mean and std for normalization (previously ImageNet stats)\n",
    "# 6. Rename validation variables to test in data export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC671-S25-TeamProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
