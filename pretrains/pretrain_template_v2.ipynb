{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e212769df2c79163",
   "metadata": {},
   "source": [
    "## Test with pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5d0748a13767e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.142931Z",
     "start_time": "2025-04-21T11:48:31.294135Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cpuinfo\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460da8d92d8804f",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143543ffa0b1711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.284882Z",
     "start_time": "2025-04-21T11:48:34.282781Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/Train\"    # paths for your training and testing dataset\n",
    "test_path = \"../data/Test\"\n",
    "input_parameter = \"\"            # paths for import and export custom model trainable parameters\n",
    "output_parameter = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61231f85",
   "metadata": {},
   "source": [
    "### Device of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "device_name = \"\"\n",
    "\n",
    "if device == torch.device(\"cuda\"):\n",
    "    device_name = torch.cuda.get_device_name(device)\n",
    "    print(f\"Using GPU: {device_name}\")\n",
    "else:\n",
    "    cpu_info = cpuinfo.get_cpu_info()\n",
    "    device_name = cpu_info['brand_raw']\n",
    "    print(f\"Using CPU: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21140ca",
   "metadata": {},
   "source": [
    "### Pretrain Model of use from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34a8a8d04cb802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.447142Z",
     "start_time": "2025-04-21T11:48:34.298297Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "#model = efficientnet_b0(weights=None)\n",
    "model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "print(f\"Using model {type(model).__name__}\")\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 32 # adjust to your memory\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,            # learning rate\n",
    "    weight_decay=1e-5,  # L2 regularization\n",
    "    betas=(0.9, 0.999), # Adam beta parameters\n",
    ")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(  # learning rate scheduler\n",
    "    optimizer,\n",
    "    T_max=epochs,               # number of epochs before restart\n",
    "    eta_min=1e-6,               # minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de4213559fc515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.465665Z",
     "start_time": "2025-04-21T11:48:34.457418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Controling randomness for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332cc4f55b5e4bf",
   "metadata": {},
   "source": [
    "### Data Loader and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6bff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset mean and std\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "num_workers = min(4, os.cpu_count() // 2)  # Dynamically set num_workers\n",
    "def compute_mean_std(dataset_path, batch_size=32, num_workers=None):\n",
    "    \"\"\"Compute channel-wise mean and standard deviation of an image dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to dataset directory (ImageFolder format)\n",
    "        batch_size: Number of images per batch\n",
    "        num_workers: Number of parallel data loading workers\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (mean, std) tensors for each channel (3 for RGB)\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),          # Resize shorter side to 224px\n",
    "        transforms.CenterCrop(224),      # Take center 224x224 crop\n",
    "        transforms.ToTensor()            # Convert to [0,1] range tensor\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,                  # Maintain deterministic order\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    mean = 0.0                          # Accumulator for mean values\n",
    "    std = 0.0                           # Accumulator for std values \n",
    "    n_images = 0                        # Total images processed\n",
    "\n",
    "    for images, _ in tqdm(loader, desc=\"Computing mean/std\"):\n",
    "        batch_size = images.size(0)\n",
    "        # Flatten spatial dimensions (height x width)\n",
    "        images = images.view(batch_size, images.size(1), -1)  # (B, C, H*W)\n",
    "\n",
    "        # Compute mean across spatial dimensions\n",
    "        mean += images.mean(2).sum(0)   # Sum per-channel means (shape [C])\n",
    "\n",
    "        # Compute unbiased std across spatial dimensions\n",
    "        std += torch.std(images, dim=2, unbiased=True).sum(0)  # [C]\n",
    "\n",
    "        n_images += batch_size\n",
    "\n",
    "    # Average across all images\n",
    "    mean /= n_images\n",
    "    std /= n_images\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_train, std_train = compute_mean_std(train_path)\n",
    "#print(f\"Train mean: {mean_train}, Train std: {std_train}\")\n",
    "#mean_test, std_test = compute_mean_std(test_path)\n",
    "#print(f\"Test mean: {mean_test}, Test std: {std_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a404b216b26a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.517225Z",
     "start_time": "2025-04-21T11:48:34.493177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform for training and testing datasets\n",
    "transform_train = transforms.Compose([          # on training dataset\n",
    "    transforms.RandomAffine(\n",
    "        degrees=15,          # Rotation range\n",
    "        translate=(0.1, 0.1),# Shift range (width, height)\n",
    "        scale=(0.9, 1.1),    # Zoom range\n",
    "        shear=10,            # Shear angle in degrees\n",
    "        fill=(128, 128, 128) # Fill color for empty areas (e.g., gray)\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),    # ImageNet mean and std\n",
    "    #transforms.Normalize(mean=mean_train.tolist(), std=std_train.tolist())\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([   # on test dataset\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    #transforms.Normalize(mean=mean_train.tolist(), std=std_train.tolist())\n",
    "    ])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "train_data = [\n",
    "    (images.to(device), labels.to(device))\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Preloading Train Data to {device_name}\", leave=False)\n",
    "]\n",
    "val_data = [\n",
    "    (images.to(device), labels.to(device))\n",
    "    for images, labels in tqdm(test_loader, desc=f\"Preloading Val Data to {device_name}\", leave=False)\n",
    "]\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2871148fc4fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.524281Z",
     "start_time": "2025-04-21T11:48:34.521216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the output layer of the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_features = model.classifier[1].in_features\n",
    "print(f\"Classifier - Input features: {num_features}, Output classes: {num_classes}\")\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(128, num_classes),\n",
    "    #nn.Softmax(dim=1)  # Use Softmax for multi-class classification (may not be needed for CrossEntropyLoss)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1795a45e3c08a75",
   "metadata": {},
   "source": [
    "### Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5db7349fc7d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.565876Z",
     "start_time": "2025-04-21T11:48:34.563196Z"
    }
   },
   "outputs": [],
   "source": [
    "# IF NEEDED\n",
    "# Load custom weight and optimizer states\n",
    "# if os.path.exists(input_parameter):\n",
    "#     checkpoint = torch.load(\"test_weights.pth\", map_location=device)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded31e95efe3a765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.588042Z",
     "start_time": "2025-04-21T11:48:34.585548Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Selective layer freezing\n",
    "# # change base on your model\n",
    "# # \"Early layers are often already well-optimized\" by ChatGPT-O4\n",
    "# for _, param in model.named_parameters():\n",
    "#     param.requires_grad = True          # Unfreeze all layers first\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"classifier\" not in name:\n",
    "#         param.requires_grad = False     # Freeze everything except the last classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247b01c5c37b276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:48:34.687917Z",
     "start_time": "2025-04-21T11:48:34.598546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "print(f\"Model is on {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "print(summary(model, (batch_size, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027cba37344acf9",
   "metadata": {},
   "source": [
    "### Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3520fd42aeea885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.251397Z",
     "start_time": "2025-04-21T11:48:34.690910Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    train_bar = tqdm(train_data, desc=f\"Epoch {epoch + 1}/{epochs} [Train]\", leave=False)\n",
    "    for images, labels in train_bar:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'loss': f\"{running_loss / total_train:.4f}\",\n",
    "            'acc': f\"{100. * correct_train / total_train:.2f}%\"\n",
    "        })\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    val_bar = tqdm(val_data, desc=f\"Epoch {epoch + 1}/{epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_bar:\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            val_bar.set_postfix({\n",
    "                'loss': f\"{val_loss / total_val:.4f}\",\n",
    "                'acc': f\"{100. * correct_val / total_val:.2f}%\"\n",
    "            })\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - \"\n",
    "          f\"Train Loss: {running_loss / total_train:.4f}, Train Acc: {100. * correct_train / total_train:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss / total_val:.4f}, Val Acc: {100. * correct_val / total_val:.2f}%\")\n",
    "    \n",
    "    # Augment the dataset if validation loss is not improving\n",
    "    if val_loss > previous_loss:\n",
    "        print(f\"Validation loss did not improve from {previous_loss / total_val:.4f}. Augmenting dataset...\")\n",
    "        del train_data\n",
    "        torch.cuda.empty_cache()\n",
    "        train_dataset = datasets.ImageFolder(root=train_path, transform=transform_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        train_data = [\n",
    "            (images.to(device), labels.to(device))\n",
    "            for images, labels in tqdm(train_loader, desc=f\"Preloading Train Data to {device_name}\", leave=False)\n",
    "        ]\n",
    "    previous_loss = min(val_loss, previous_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f05590085d19fe",
   "metadata": {},
   "source": [
    "### Training log and data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbef08ee604230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T12:11:52.411762Z",
     "start_time": "2025-04-21T12:11:52.409200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "# iteration 3 template 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC671-S25-TeamProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
